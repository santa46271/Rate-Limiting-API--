# Буферизованный читатель-писатель

## Контекст: Представьте себе сценарий, где данные поступают из потока (например, Kafka) небольшими порциями, но их необходимо накапливать и крупными батчами отправлять в систему хранения или анализа (например, ClickHouse), которая работает с такими батчами гораздо эффективнее.

## Интерфейсы

```go
// Producer источник данных.
type Producer interface {
    // Next возвращает следующую порцию данных.
    // Возвращает:
    // - items: слайс с данными для обработки (не более MaxItems)
    // - cookie: идентификатор, который необходимо подтвердить (commit) после успешной обработки *всех* items
    // - err: ошибка, если таковая возникла
    Next() (items []any, cookie int, err error)
    
    // Commit подтверждает успешную обработку всех данных, связанных с переданным cookie.
    // Cookie должны подтверждаться строго в том порядке, в котором они были получены.
    Commit(cookie int) error
}

// Consumer потребитель данных.
type Consumer interface {
    // Process обрабатывает переданный батч данных.
    // Размер батча items не должен превышать MaxItems.
    Process(items []any) error
}
```

## Задача: Реализовать функцию Pipe, которая эффективно передает данные от Producer к Consumer, агрегируя мелкие пакеты в крупные для оптимизации производительности.

```go
// Pipe читает данные из Producer, накапливает их до размера не более MaxItems
// и отправляет на обработку в Consumer. После успешной обработки батча
// функция должна подтвердить все соответствующие cookie в источнике.
// Функция возвращает ошибку, если любой из методов Producer или Consumer вернул ошибку.
func Pipe(p Producer, c Consumer) error {
    // Ваша реализация здесь
}
```

## Усложнение:
Методы Next, Process и Commit связаны с сетевыми вызовами и могут работать довоьно долго.
Для ускорения процесса передачи нужно распараллелить процессы чтения, записи и подтверждения прогресса.
